{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"Generates a batch iterator for a dataset.\"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    if len(data) % batch_size == 0:\n",
    "        num_batches_per_epoch = int(len(data) / batch_size)\n",
    "    else:\n",
    "        num_batches_per_epoch = int(len(data) / batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(np.arange(data_size))\n",
    "        else:\n",
    "            indices = np.arange(data_size)\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield data[indices[start_index:end_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "num_steps = 20\n",
    "n_hidden = 4\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in batches:\n",
    "    x_batch, y_batch = zip(*batch)\n",
    "    x_batch, y_batch = np.array(x_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Build graph ##\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# input\n",
    "x_input = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "y_input = tf.placeholder(tf.int32, [batch_size, num_steps])\n",
    "init_state = tf.zeros([batch_size, n_hidden])\n",
    "\n",
    "x = tf.one_hot(x_input, 2)\n",
    "x = tf.unpack(x, axis=1)\n",
    "\n",
    "# GRU cell\n",
    "gru_cell = tf.nn.rnn_cell.GRUCell(n_hidden)\n",
    "outputs, final_state = tf.nn.rnn(gru_cell, x, initial_state = init_state)\n",
    "\n",
    "# To output\n",
    "W_out = tf.get_variable('W_out', [n_hidden, 2])\n",
    "b_out = tf.get_variable('b_out', [2], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits = [tf.matmul(o, W_out) + b_out for o in outputs]\n",
    "predictions = [tf.nn.softmax(l) for l in logits]\n",
    "\n",
    "y_as_list = [tf.squeeze(y, squeeze_dims=[1]) for y in tf.split(1, num_steps, y_input)]\n",
    "loss_weights = [tf.zeros([batch_size]) if i < 8 else tf.ones([batch_size]) for i in range(num_steps)]\n",
    "\n",
    "# Cost and training\n",
    "losses = tf.nn.seq2seq.sequence_loss_by_example(logits, y_as_list, loss_weights)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X,Y) = gen_data()\n",
    "X = np.reshape(X, [-1, num_steps])\n",
    "Y = np.reshape(Y, [-1, num_steps])\n",
    "\n",
    "batches = batch_iter(list(zip(X,Y)), batch_size = batch_size, num_epochs = 2)\n",
    "\n",
    "acc_loss = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i, batch in enumerate(batches):\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        x_batch, y_batch = np.array(x_batch), np.array(y_batch)\n",
    "        feed_dict = {x_input : x_batch,\n",
    "                     y_input : y_batch\n",
    "                     }\n",
    "        loss, _ = sess.run([total_loss, train_step], feed_dict=feed_dict)\n",
    "        acc_loss += loss\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(acc_loss/100)\n",
    "            acc_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
