{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if i >= 3 and X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if i >= 8 and X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            X[i] = 0\n",
    "        else:\n",
    "            X[i] = 1\n",
    "    return X\n",
    "def gen_data_sequence(examples=50000, num_seq = 2, num_steps = 21):\n",
    "    X = np.zeros([examples, num_seq, num_steps])\n",
    "    for i in range(examples):\n",
    "        for j in range(num_seq*num_steps):\n",
    "            jj, kk = divmod(j,num_steps)\n",
    "            if ((j + 1) % num_steps == 0):\n",
    "                X[i,jj, kk] = 2 # EOL character\n",
    "                continue\n",
    "            threshold = 0.5\n",
    "            j3, k3 = divmod(j - 3, num_steps)\n",
    "            j8, k8 = divmod(j - 8, num_steps)\n",
    "            if j >= 3 and X[i,j3, k3] == 1:\n",
    "                threshold += 0.5\n",
    "            if j >= 8 and X[i,j8, k8] == 1:\n",
    "                threshold -= 0.25\n",
    "            if np.random.rand() > threshold:\n",
    "                X[i,jj,kk] = 0\n",
    "            else:\n",
    "                X[i,jj,kk] = 1\n",
    "    return X\n",
    "\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"Generates a batch iterator for a dataset.\"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    if len(data) % batch_size == 0:\n",
    "        num_batches_per_epoch = int(len(data) / batch_size)\n",
    "    else:\n",
    "        num_batches_per_epoch = int(len(data) / batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(np.arange(data_size))\n",
    "        else:\n",
    "            indices = np.arange(data_size)\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            if end_index - start_index != batch_size:\n",
    "                continue\n",
    "            yield data[indices[start_index:end_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "num_steps = 20\n",
    "num_seq = 2\n",
    "n_hidden_enc = 4\n",
    "n_hidden_dec = 8\n",
    "batch_size = 200\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Build graph ##\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# input\n",
    "sequence_input = tf.placeholder(tf.int32, [batch_size, num_seq, num_steps])\n",
    "\n",
    "sequence = tf.one_hot(sequence_input, 3) # [batch_size, num_seq, num_steps, 1-hot]\n",
    "sequence = tf.unpack(sequence, axis=1) # list(num_seq * [batch_size, num_steps, 1-hot])\n",
    "x, y = sequence[0], sequence[1]\n",
    "\n",
    "x = tf.unpack(x, axis = 1) # list(num_steps * [batch_size, 1-hot])\n",
    "y = tf.unpack(y, axis = 1) # list(num_steps * [batch_size, 1-hot])\n",
    "\n",
    "# Encoder\n",
    "init_state_enc = tf.zeros([batch_size, n_hidden_enc])\n",
    "encoder_cell = tf.nn.rnn_cell.GRUCell(n_hidden_enc)\n",
    "_, final_state_enc = tf.nn.rnn(encoder_cell, x, initial_state = init_state_enc)\n",
    "\n",
    "# Encoder to decoder\n",
    "W_enc_to_dec = tf.get_variable('W_enc_to_dec', [n_hidden_enc, n_hidden_dec])\n",
    "init_state_dec = tf.matmul(final_state_enc, W_enc_to_dec)\n",
    "\n",
    "# Decoder\n",
    "y = [tf.zeros([batch_size, 3])] + y \n",
    "decoder_cell = tf.nn.rnn_cell.GRUCell(n_hidden_dec)\n",
    "outputs, _ = tf.nn.seq2seq.rnn_decoder(y[:-1], init_state_dec, decoder_cell)\n",
    "\n",
    "# To output\n",
    "W_out = tf.get_variable('W_out', [n_hidden_dec, 3])\n",
    "b_out = tf.get_variable('b_out', [3])\n",
    "\n",
    "logits = [tf.matmul(o, W_out) + b_out for o in outputs]\n",
    "predictions = [tf.nn.softmax(l) for l in logits]\n",
    "\n",
    "y = [tf.argmax(yv, 1) for i, yv in enumerate(y) if i > 0]\n",
    "loss_weights = [tf.ones([batch_size]) for i in range(num_steps)]\n",
    "\n",
    "# Cost and training\n",
    "losses = tf.nn.seq2seq.sequence_loss_by_example(logits, y, loss_weights)\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(total_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = gen_data_sequence()\n",
    "X = np.reshape(X, [-1, num_seq, num_steps])\n",
    "\n",
    "batches = batch_iter(list(X), batch_size = batch_size, num_epochs = 3)\n",
    "\n",
    "acc_loss = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i, batch in enumerate(batches):\n",
    "        x_batch = np.array(batch)\n",
    "        feed_dict = {sequence_input : x_batch,\n",
    "                     }\n",
    "        loss, _ = sess.run([total_loss, train_step], feed_dict=feed_dict)\n",
    "        acc_loss += loss\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(acc_loss/100)\n",
    "            acc_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
